{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI - Heart Attack Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary objective of this notebook is to load this dataset of which is derived from the CDC's, Behavioral Risk Factor Surveillance System (BRFSS), which is self answered, survery data. This dataset has a total of 400K+ responses across the United States and is the data I will be loading to use within the HAI project. \n",
    "\n",
    "Given the critical importance of cardiovascular diseases as a leading cause of mortality globally, identifying and understanding the factors contributing to heart attacks is imperative. This dataset includes a multitude of variables related to health conditions, which are potentially associated with heart disease. In this initial phase, we will focus on the following key tasks:\n",
    "\n",
    " - Data Importation: Importing the full CDC dataset with null values.\n",
    "\n",
    "By the end of this notebook, we aim to have a clean, well-understood dataset that is ready for Exploratory Data Analysis (EDA) in the next notebook. This step is crucial as it sets the stage for accurate and insightful analyses that may further inform the health sector of the importance of features most decisive of heart attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3 libraries need to be imported pandas, numpy and matplotlib.pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Libraries \n",
    "import pandas as pd # pandas library \n",
    "import numpy as np # numpy library\n",
    "import matplotlib.pyplot as plt # Import the pyplot (pythonplot) part of the matlotlib library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Perameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the global parameters for the project, 8.0 and 6.0 is a good universal size for plots to be shown with enough context, while not squishing anything so it is unreadable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all dataframe columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Set matplotlib global settings\n",
    "plt.rcParams['figure.figsize'] = (8.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the helper functions used to help with this project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions dq_checks, is a sanity check function that allows me to look through a dataframe and return a irregularities description of the dataframe specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the data for everything stated below\n",
    "def dq_checks(df):\n",
    "    print(\"+----------DataFrame Quality Report----------+\")\n",
    "    n_rows, n_cols=df.shape\n",
    "    n_nulls = df.isna().sum().sum() # 2 sums - total null values for all columns\n",
    "    n_row_dups = df.duplicated().sum()\n",
    "    n_col_dups = df.T.duplicated().sum() # transpost the column for a duplicated column\n",
    "    return (\n",
    "    f\"\"\"\n",
    "    No. of rows: {n_rows}\n",
    "    No. of columns: {n_cols}\n",
    "    No. of missing values: {n_nulls}\n",
    "    No. of duplicated rows: {n_row_dups}\n",
    "    No. of duplicated columns: {n_col_dups}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data needed to progress with the capstone project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading for github only\n",
    "\n",
    "CLN_DATA_PATH='../data/heart_2022_with_nans.csv'\n",
    "\n",
    "try:\n",
    "    heart_attack_raw = pd.read_csv(CLN_DATA_PATH)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: The data file does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I successfully imported the heart_2022_with_nans.csv dataset. This dataset will serve as the main dataset for our analysis of heart attack indicators. By loading this dataset, I have established a foundation for the subsequent Exploratory Data Analysis (EDA) notebook.\n",
    "\n",
    "The next steps will involve a detailed inspection, data cleaning and insight extraction which will be carried out in the EDA notebook. Ensuring the integrity and readiness of our data is crucial as I progress towards identifying and understanding the factors that contribute to heart disease. The meticulous preparation of our dataset will enable us to derive meaningful insights and potentially implament public health strategies aimed at reducing the prevalence of heart attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
